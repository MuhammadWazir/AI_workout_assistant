{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\user\\.vscode\\extensions\\ms-python.python-2024.22.0-win32-x64\\python_files\\python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 10, in <module>\n",
       "ModuleNotFoundError: No module named 'keras_tuner'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"./test.csv\")\n",
    "test_dataset.columns\n",
    "train_dataset = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "RangeIndex: 710 entries, 0 to 709\n",
       "Data columns (total 69 columns):\n",
       " #   Column              Non-Null Count  Dtype  \n",
       "---  ------              --------------  -----  \n",
       " 0   label               710 non-null    object \n",
       " 1   nose_x              710 non-null    float64\n",
       " 2   nose_y              710 non-null    float64\n",
       " 3   nose_z              710 non-null    float64\n",
       " 4   nose_v              710 non-null    float64\n",
       " 5   left_shoulder_x     710 non-null    float64\n",
       " 6   left_shoulder_y     710 non-null    float64\n",
       " 7   left_shoulder_z     710 non-null    float64\n",
       " 8   left_shoulder_v     710 non-null    float64\n",
       " 9   right_shoulder_x    710 non-null    float64\n",
       " 10  right_shoulder_y    710 non-null    float64\n",
       " 11  right_shoulder_z    710 non-null    float64\n",
       " 12  right_shoulder_v    710 non-null    float64\n",
       " 13  left_elbow_x        710 non-null    float64\n",
       " 14  left_elbow_y        710 non-null    float64\n",
       " 15  left_elbow_z        710 non-null    float64\n",
       " 16  left_elbow_v        710 non-null    float64\n",
       " 17  right_elbow_x       710 non-null    float64\n",
       " 18  right_elbow_y       710 non-null    float64\n",
       " 19  right_elbow_z       710 non-null    float64\n",
       " 20  right_elbow_v       710 non-null    float64\n",
       " 21  left_wrist_x        710 non-null    float64\n",
       " 22  left_wrist_y        710 non-null    float64\n",
       " 23  left_wrist_z        710 non-null    float64\n",
       " 24  left_wrist_v        710 non-null    float64\n",
       " 25  right_wrist_x       710 non-null    float64\n",
       " 26  right_wrist_y       710 non-null    float64\n",
       " 27  right_wrist_z       710 non-null    float64\n",
       " 28  right_wrist_v       710 non-null    float64\n",
       " 29  left_hip_x          710 non-null    float64\n",
       " 30  left_hip_y          710 non-null    float64\n",
       " 31  left_hip_z          710 non-null    float64\n",
       " 32  left_hip_v          710 non-null    float64\n",
       " 33  right_hip_x         710 non-null    float64\n",
       " 34  right_hip_y         710 non-null    float64\n",
       " 35  right_hip_z         710 non-null    float64\n",
       " 36  right_hip_v         710 non-null    float64\n",
       " 37  left_knee_x         710 non-null    float64\n",
       " 38  left_knee_y         710 non-null    float64\n",
       " 39  left_knee_z         710 non-null    float64\n",
       " 40  left_knee_v         710 non-null    float64\n",
       " 41  right_knee_x        710 non-null    float64\n",
       " 42  right_knee_y        710 non-null    float64\n",
       " 43  right_knee_z        710 non-null    float64\n",
       " 44  right_knee_v        710 non-null    float64\n",
       " 45  left_ankle_x        710 non-null    float64\n",
       " 46  left_ankle_y        710 non-null    float64\n",
       " 47  left_ankle_z        710 non-null    float64\n",
       " 48  left_ankle_v        710 non-null    float64\n",
       " 49  right_ankle_x       710 non-null    float64\n",
       " 50  right_ankle_y       710 non-null    float64\n",
       " 51  right_ankle_z       710 non-null    float64\n",
       " 52  right_ankle_v       710 non-null    float64\n",
       " 53  left_heel_x         710 non-null    float64\n",
       " 54  left_heel_y         710 non-null    float64\n",
       " 55  left_heel_z         710 non-null    float64\n",
       " 56  left_heel_v         710 non-null    float64\n",
       " 57  right_heel_x        710 non-null    float64\n",
       " 58  right_heel_y        710 non-null    float64\n",
       " 59  right_heel_z        710 non-null    float64\n",
       " 60  right_heel_v        710 non-null    float64\n",
       " 61  left_foot_index_x   710 non-null    float64\n",
       " 62  left_foot_index_y   710 non-null    float64\n",
       " 63  left_foot_index_z   710 non-null    float64\n",
       " 64  left_foot_index_v   710 non-null    float64\n",
       " 65  right_foot_index_x  710 non-null    float64\n",
       " 66  right_foot_index_y  710 non-null    float64\n",
       " 67  right_foot_index_z  710 non-null    float64\n",
       " 68  right_foot_index_v  710 non-null    float64\n",
       "dtypes: float64(68), object(1)\n",
       "memory usage: 382.9+ KB\n",
       "<class 'pandas.core.frame.DataFrame'>\n",
       "RangeIndex: 28520 entries, 0 to 28519\n",
       "Data columns (total 69 columns):\n",
       " #   Column              Non-Null Count  Dtype  \n",
       "---  ------              --------------  -----  \n",
       " 0   label               28520 non-null  object \n",
       " 1   nose_x              28520 non-null  float64\n",
       " 2   nose_y              28520 non-null  float64\n",
       " 3   nose_z              28520 non-null  float64\n",
       " 4   nose_v              28520 non-null  float64\n",
       " 5   left_shoulder_x     28520 non-null  float64\n",
       " 6   left_shoulder_y     28520 non-null  float64\n",
       " 7   left_shoulder_z     28520 non-null  float64\n",
       " 8   left_shoulder_v     28520 non-null  float64\n",
       " 9   right_shoulder_x    28520 non-null  float64\n",
       " 10  right_shoulder_y    28520 non-null  float64\n",
       " 11  right_shoulder_z    28520 non-null  float64\n",
       " 12  right_shoulder_v    28520 non-null  float64\n",
       " 13  left_elbow_x        28520 non-null  float64\n",
       " 14  left_elbow_y        28520 non-null  float64\n",
       " 15  left_elbow_z        28520 non-null  float64\n",
       " 16  left_elbow_v        28520 non-null  float64\n",
       " 17  right_elbow_x       28520 non-null  float64\n",
       " 18  right_elbow_y       28520 non-null  float64\n",
       " 19  right_elbow_z       28520 non-null  float64\n",
       " 20  right_elbow_v       28520 non-null  float64\n",
       " 21  left_wrist_x        28520 non-null  float64\n",
       " 22  left_wrist_y        28520 non-null  float64\n",
       " 23  left_wrist_z        28520 non-null  float64\n",
       " 24  left_wrist_v        28520 non-null  float64\n",
       " 25  right_wrist_x       28520 non-null  float64\n",
       " 26  right_wrist_y       28520 non-null  float64\n",
       " 27  right_wrist_z       28520 non-null  float64\n",
       " 28  right_wrist_v       28520 non-null  float64\n",
       " 29  left_hip_x          28520 non-null  float64\n",
       " 30  left_hip_y          28520 non-null  float64\n",
       " 31  left_hip_z          28520 non-null  float64\n",
       " 32  left_hip_v          28520 non-null  float64\n",
       " 33  right_hip_x         28520 non-null  float64\n",
       " 34  right_hip_y         28520 non-null  float64\n",
       " 35  right_hip_z         28520 non-null  float64\n",
       " 36  right_hip_v         28520 non-null  float64\n",
       " 37  left_knee_x         28520 non-null  float64\n",
       " 38  left_knee_y         28520 non-null  float64\n",
       " 39  left_knee_z         28520 non-null  float64\n",
       " 40  left_knee_v         28520 non-null  float64\n",
       " 41  right_knee_x        28520 non-null  float64\n",
       " 42  right_knee_y        28520 non-null  float64\n",
       " 43  right_knee_z        28520 non-null  float64\n",
       " 44  right_knee_v        28520 non-null  float64\n",
       " 45  left_ankle_x        28520 non-null  float64\n",
       " 46  left_ankle_y        28520 non-null  float64\n",
       " 47  left_ankle_z        28520 non-null  float64\n",
       " 48  left_ankle_v        28520 non-null  float64\n",
       " 49  right_ankle_x       28520 non-null  float64\n",
       " 50  right_ankle_y       28520 non-null  float64\n",
       " 51  right_ankle_z       28520 non-null  float64\n",
       " 52  right_ankle_v       28520 non-null  float64\n",
       " 53  left_heel_x         28520 non-null  float64\n",
       " 54  left_heel_y         28520 non-null  float64\n",
       " 55  left_heel_z         28520 non-null  float64\n",
       " 56  left_heel_v         28520 non-null  float64\n",
       " 57  right_heel_x        28520 non-null  float64\n",
       " 58  right_heel_y        28520 non-null  float64\n",
       " 59  right_heel_z        28520 non-null  float64\n",
       " 60  right_heel_v        28520 non-null  float64\n",
       " 61  left_foot_index_x   28520 non-null  float64\n",
       " 62  left_foot_index_y   28520 non-null  float64\n",
       " 63  left_foot_index_z   28520 non-null  float64\n",
       " 64  left_foot_index_v   28520 non-null  float64\n",
       " 65  right_foot_index_x  28520 non-null  float64\n",
       " 66  right_foot_index_y  28520 non-null  float64\n",
       " 67  right_foot_index_z  28520 non-null  float64\n",
       " 68  right_foot_index_v  28520 non-null  float64\n",
       "dtypes: float64(68), object(1)\n",
       "memory usage: 15.0+ MB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset.shape\n",
    "test_dataset.info()\n",
    "test_dataset.describe()\n",
    "\n",
    "train_dataset.shape\n",
    "train_dataset.info()\n",
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>nose_z</th>\n",
       "      <th>nose_v</th>\n",
       "      <th>left_shoulder_x</th>\n",
       "      <th>left_shoulder_y</th>\n",
       "      <th>left_shoulder_z</th>\n",
       "      <th>left_shoulder_v</th>\n",
       "      <th>right_shoulder_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_heel_z</th>\n",
       "      <th>right_heel_v</th>\n",
       "      <th>left_foot_index_x</th>\n",
       "      <th>left_foot_index_y</th>\n",
       "      <th>left_foot_index_z</th>\n",
       "      <th>left_foot_index_v</th>\n",
       "      <th>right_foot_index_x</th>\n",
       "      <th>right_foot_index_y</th>\n",
       "      <th>right_foot_index_z</th>\n",
       "      <th>right_foot_index_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.241842</td>\n",
       "      <td>0.435841</td>\n",
       "      <td>-0.002772</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.274594</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>-0.188556</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>0.296270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174394</td>\n",
       "      <td>0.529667</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.555134</td>\n",
       "      <td>-0.070554</td>\n",
       "      <td>0.776038</td>\n",
       "      <td>0.794738</td>\n",
       "      <td>0.537268</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>0.440595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>0.237662</td>\n",
       "      <td>0.440657</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.274228</td>\n",
       "      <td>0.339355</td>\n",
       "      <td>-0.189618</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184522</td>\n",
       "      <td>0.553936</td>\n",
       "      <td>0.803268</td>\n",
       "      <td>0.557891</td>\n",
       "      <td>-0.061299</td>\n",
       "      <td>0.799590</td>\n",
       "      <td>0.795147</td>\n",
       "      <td>0.533265</td>\n",
       "      <td>0.113687</td>\n",
       "      <td>0.479885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.237591</td>\n",
       "      <td>0.441506</td>\n",
       "      <td>-0.003623</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.274257</td>\n",
       "      <td>0.340742</td>\n",
       "      <td>-0.190390</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.295690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187280</td>\n",
       "      <td>0.553449</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.558061</td>\n",
       "      <td>-0.053722</td>\n",
       "      <td>0.798296</td>\n",
       "      <td>0.797029</td>\n",
       "      <td>0.534547</td>\n",
       "      <td>0.120511</td>\n",
       "      <td>0.478705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>0.238127</td>\n",
       "      <td>0.441322</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.274333</td>\n",
       "      <td>0.339990</td>\n",
       "      <td>-0.190143</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.295731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178452</td>\n",
       "      <td>0.561389</td>\n",
       "      <td>0.803932</td>\n",
       "      <td>0.554631</td>\n",
       "      <td>-0.059433</td>\n",
       "      <td>0.804831</td>\n",
       "      <td>0.799963</td>\n",
       "      <td>0.532089</td>\n",
       "      <td>0.107540</td>\n",
       "      <td>0.488323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>0.238066</td>\n",
       "      <td>0.440833</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.274171</td>\n",
       "      <td>0.343735</td>\n",
       "      <td>-0.187406</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.295011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172571</td>\n",
       "      <td>0.567620</td>\n",
       "      <td>0.802851</td>\n",
       "      <td>0.554338</td>\n",
       "      <td>-0.064519</td>\n",
       "      <td>0.809826</td>\n",
       "      <td>0.799751</td>\n",
       "      <td>0.530627</td>\n",
       "      <td>0.102761</td>\n",
       "      <td>0.495874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label    nose_x    nose_y    nose_z    nose_v  left_shoulder_x  \\\n",
       "0     C  0.241842  0.435841 -0.002772  0.999881         0.274594   \n",
       "1     C  0.237662  0.440657 -0.003768  0.999896         0.274228   \n",
       "2     C  0.237591  0.441506 -0.003623  0.999899         0.274257   \n",
       "3     C  0.238127  0.441322 -0.000322  0.999902         0.274333   \n",
       "4     C  0.238066  0.440833  0.003989  0.999907         0.274171   \n",
       "\n",
       "   left_shoulder_y  left_shoulder_z  left_shoulder_v  right_shoulder_x  ...  \\\n",
       "0         0.341100        -0.188556         0.999743          0.296270  ...   \n",
       "1         0.339355        -0.189618         0.999759          0.296200  ...   \n",
       "2         0.340742        -0.190390         0.999762          0.295690  ...   \n",
       "3         0.339990        -0.190143         0.999760          0.295731  ...   \n",
       "4         0.343735        -0.187406         0.999760          0.295011  ...   \n",
       "\n",
       "   right_heel_z  right_heel_v  left_foot_index_x  left_foot_index_y  \\\n",
       "0      0.174394      0.529667           0.801527           0.555134   \n",
       "1      0.184522      0.553936           0.803268           0.557891   \n",
       "2      0.187280      0.553449           0.803358           0.558061   \n",
       "3      0.178452      0.561389           0.803932           0.554631   \n",
       "4      0.172571      0.567620           0.802851           0.554338   \n",
       "\n",
       "   left_foot_index_z  left_foot_index_v  right_foot_index_x  \\\n",
       "0          -0.070554           0.776038            0.794738   \n",
       "1          -0.061299           0.799590            0.795147   \n",
       "2          -0.053722           0.798296            0.797029   \n",
       "3          -0.059433           0.804831            0.799963   \n",
       "4          -0.064519           0.809826            0.799751   \n",
       "\n",
       "   right_foot_index_y  right_foot_index_z  right_foot_index_v  \n",
       "0            0.537268            0.102899            0.440595  \n",
       "1            0.533265            0.113687            0.479885  \n",
       "2            0.534547            0.120511            0.478705  \n",
       "3            0.532089            0.107540            0.488323  \n",
       "4            0.530627            0.102761            0.495874  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "C    9904\n",
       "L    9546\n",
       "H    9070\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTANT_LMS = [\n",
    "    \"NOSE\",\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"LEFT_ELBOW\",\n",
    "    \"RIGHT_ELBOW\",\n",
    "    \"LEFT_WRIST\",\n",
    "    \"RIGHT_WRIST\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "    \"LEFT_KNEE\",\n",
    "    \"RIGHT_KNEE\",\n",
    "    \"LEFT_ANKLE\",\n",
    "    \"RIGHT_ANKLE\",\n",
    "    \"LEFT_HEEL\",\n",
    "    \"RIGHT_HEEL\",\n",
    "    \"LEFT_FOOT_INDEX\",\n",
    "    \"RIGHT_FOOT_INDEX\",\n",
    "]\n",
    "\n",
    "HEADERS = [\"label\"]\n",
    "\n",
    "for lm in IMPORTANT_LMS:\n",
    "    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v', 'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v', 'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v', 'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v', 'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v', 'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v', 'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v', 'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z', 'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y', 'right_foot_index_z', 'right_foot_index_v']\n",
       "Number of rows: 28520 \n",
       "Number of columns: 69\n",
       "\n",
       "Labels: \n",
       "label\n",
       "C    9904\n",
       "L    9546\n",
       "H    9070\n",
       "Name: count, dtype: int64\n",
       "\n",
       "Missing values: False\n",
       "\n",
       "Duplicate Rows : 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def describe_dataset(dataset_path: str):\n",
    "    '''\n",
    "    Describe dataset\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    print(f\"Headers: {list(data.columns.values)}\")\n",
    "    print(f'Number of rows: {data.shape[0]} \\nNumber of columns: {data.shape[1]}\\n')\n",
    "    print(f\"Labels: \\n{data['label'].value_counts()}\\n\")\n",
    "    print(f\"Missing values: {data.isnull().values.any()}\\n\")\n",
    "    \n",
    "    duplicate = data[data.duplicated()]\n",
    "    print(f\"Duplicate Rows : {len(duplicate.sum(axis=1))}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def remove_duplicate_rows(dataset_path: str):\n",
    "    '''\n",
    "    Remove duplicated data from the dataset then save it to another files\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    df.to_csv(f\"cleaned_train.csv\", sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "def round_up_metric_results(results) -> list:\n",
    "    '''Round up metrics results such as precision score, recall score, ...'''\n",
    "    return list(map(lambda el: round(el, 3), results))\n",
    "\n",
    "\n",
    "df = describe_dataset(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of rows: 28520 \n",
       "Number of columns: 69\n",
       "\n",
       "Labels: \n",
       "label\n",
       "0    9904\n",
       "2    9546\n",
       "1    9070\n",
       "Name: count, dtype: int64\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "df.loc[df[\"label\"] == \"C\", \"label\"] = 0\n",
    "df.loc[df[\"label\"] == \"H\", \"label\"] = 1\n",
    "df.loc[df[\"label\"] == \"L\", \"label\"] = 2\n",
    "\n",
    "print(f'Number of rows: {df.shape[0]} \\nNumber of columns: {df.shape[1]}\\n')\n",
    "print(f\"Labels: \\n{df['label'].value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x',\n",
       "       'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v',\n",
       "       'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z',\n",
       "       'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z',\n",
       "       'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z',\n",
       "       'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z',\n",
       "       'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z',\n",
       "       'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v',\n",
       "       'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v',\n",
       "       'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v',\n",
       "       'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v',\n",
       "       'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v',\n",
       "       'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v',\n",
       "       'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v',\n",
       "       'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v',\n",
       "       'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z',\n",
       "       'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y',\n",
       "       'right_foot_index_z', 'right_foot_index_v'],\n",
       "      dtype='object')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard Scaling of features\n",
    "# Dump input scaler\n",
    "with open(\"./input_scaler.pkl\", \"rb\") as f2:\n",
    "    sc = pickle.load(f2)\n",
    "\n",
    "x = df.drop(\"label\", axis = 1)\n",
    "x = pd.DataFrame(sc.transform(x))\n",
    "\n",
    "y = df[\"label\"]\n",
    "\n",
    "# # Converting prediction to categorical\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "print(df.drop(\"label\", axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x.values, y_cat, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "# Final Results\n",
    "final_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model(model):\n",
    "    '''\n",
    "    Describe Model architecture\n",
    "    '''\n",
    "    print(f\"Describe models architecture\")\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        number_of_units = layer.units if hasattr(layer, 'units') else 0\n",
    "\n",
    "        if hasattr(layer, \"activation\"):\n",
    "            print(f\"Layer-{i + 1}: {number_of_units} units, func: \", layer.activation)\n",
    "        else:\n",
    "            print(f\"Layer-{i + 1}: {number_of_units} units, func: None\")\n",
    "            \n",
    "\n",
    "def get_best_model(tuner):\n",
    "    '''\n",
    "    Describe and return the best model found from keras tuner\n",
    "    '''\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    describe_model(best_model)\n",
    "\n",
    "    print(\"\\nOther params:\")\n",
    "    ignore_params = [\"tuner\", \"activation\", \"layer\"]\n",
    "    for param, value in best_hps.values.items():\n",
    "        if not any(word in param for word in ignore_params):\n",
    "            print(f\"{param}: {value}\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(68, input_dim = 68, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 18s]\n",
      "accuracy: 0.9990357756614685\n",
      "\n",
      "Best accuracy So Far: 0.9993863701820374\n",
      "Total elapsed time: 00h 05m 12s\n"
     ]
    }
   ],
   "source": [
    "tuner_3l = kt.Hyperband(\n",
    "    model_3l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "tuner_3l.search(x_train, y_train, epochs=10, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 68 units, func:  <function relu at 0x000001D53EAB59E0>\n",
      "Layer-2: 480 units, func:  <function relu at 0x000001D53EAB59E0>\n",
      "Layer-3: 3 units, func:  <function softmax at 0x000001D558CABEC0>\n",
      "\n",
      "Other params:\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.1062 - val_accuracy: 0.9979 - val_loss: 0.0095\n",
      "Epoch 2/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0103 - val_accuracy: 0.9988 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0116 - val_accuracy: 0.9981 - val_loss: 0.0065\n",
      "Epoch 4/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9993 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0065 - val_accuracy: 0.9993 - val_loss: 0.0030\n",
      "Epoch 6/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0048 - val_accuracy: 0.9995 - val_loss: 0.0022\n",
      "Epoch 7/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.9986 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0073 - val_accuracy: 0.9982 - val_loss: 0.0061\n",
      "Epoch 9/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 0.9993 - val_loss: 0.0018\n",
      "Epoch 10/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9986 - val_loss: 0.0040\n",
      "Epoch 11/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0064 - val_accuracy: 0.9993 - val_loss: 0.0025\n",
      "Epoch 12/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.9975 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.9989 - val_loss: 0.0033\n",
      "Epoch 14/100\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 0.9974 - val_loss: 0.0058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d55ee6f380>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3l = get_best_model(tuner_3l)\n",
    "model_3l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"3_layers\"] = model_3l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_5l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(68, input_dim = 68, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 37s]\n",
      "accuracy: 0.9992548823356628\n",
      "\n",
      "Best accuracy So Far: 0.999430239200592\n",
      "Total elapsed time: 00h 08m 29s\n"
     ]
    }
   ],
   "source": [
    "tuner_5l = kt.Hyperband(\n",
    "    model_5l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_1'\n",
    ")\n",
    "tuner_5l.search(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5l = get_best_model(tuner_5l)\n",
    "model_5l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"5_layers\"] = model_5l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7lD_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(68, input_dim = 68, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_dropout_1 = hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_dropout_2 = hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dropout(rate=hp_dropout_1))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dropout(rate=hp_dropout_2))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_7lD = kt.Hyperband(\n",
    "    model_7lD_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_4'\n",
    ")\n",
    "tuner_7lD.search(x_train, y_train, epochs=10, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7lD = get_best_model(tuner_7lD)\n",
    "model_7lD.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"7_layers_with_dropout\"] = model_7lD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(68, input_dim = 68, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_4 = hp.Int('layer_4', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_5 = hp.Int('layer_5', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_4, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_5, activation=hp_activation))\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_7l = kt.Hyperband(\n",
    "    model_7l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_5'\n",
    ")\n",
    "tuner_7l.search(x_train, y_train, epochs=10, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7l = get_best_model(tuner_7l)\n",
    "model_7l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"7_layers\"] = model_7l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in final_models.items():\n",
    "    print(f\"{name}: \", end=\"\")\n",
    "    describe_model(model)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Evaluate model\n",
    "    predict_x = model.predict(x_test, verbose=False) \n",
    "    y_pred_class = np.argmax(predict_x, axis=1)\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    (p_score, r_score, f_score, _) = precision_recall_fscore_support(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    \n",
    "    train_set_results.append(( name, round_up_metric_results(p_score), round_up_metric_results(r_score), round_up_metric_results(f_score), cm ))\n",
    "\n",
    "train_set_results.sort(key=lambda k: sum(k[3]), reverse=True)\n",
    "pd.DataFrame(train_set_results, columns=[\"Model\", \"Precision Score\", \"Recall Score\", \"F1 score\", \"Confusion Matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# Categorizing label\n",
    "test_df.loc[test_df[\"label\"] == \"C\", \"label\"] = 0\n",
    "test_df.loc[test_df[\"label\"] == \"H\", \"label\"] = 1\n",
    "test_df.loc[test_df[\"label\"] == \"L\", \"label\"] = 2\n",
    "\n",
    "print(f'Number of rows: {test_df.shape[0]} \\nNumber of columns: {test_df.shape[1]}\\n')\n",
    "print(f\"Labels: \\n{test_df['label'].value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling of features\n",
    "test_x = test_df.drop(\"label\", axis = 1)\n",
    "test_x = pd.DataFrame(sc.transform(test_x))\n",
    "\n",
    "test_y = test_df[\"label\"]\n",
    "\n",
    "# # Converting prediction to categorical\n",
    "test_y_cat = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Evaluate model\n",
    "    predict_x = model.predict(test_x, verbose=False) \n",
    "    y_pred_class = np.argmax(predict_x, axis=1)\n",
    "    y_test_class = np.argmax(test_y_cat, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    (p_score, r_score, f_score, _) = precision_recall_fscore_support(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    \n",
    "    test_set_results.append(( name, round_up_metric_results(p_score), round_up_metric_results(r_score), round_up_metric_results(f_score), cm ))\n",
    "\n",
    "test_set_results.sort(key=lambda k: sum(k[3]), reverse=True)\n",
    "pd.DataFrame(test_set_results, columns=[\"Model\", \"Precision Score\", \"Recall Score\", \"F1 score\", \"Confusion Matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the best model to a pickle file\n",
    "with open(\"./model/plank_dp.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_models[\"7_layers_with_dropout\"], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump final results\n",
    "with open(\"./model/all_dp.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_models, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
